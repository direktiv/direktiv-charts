# -- enable debug across all direktiv components
debug: false

# -- knative eventing enabled, requires knative setup and configuration
eventing:
  enabled: false

# -- json or console logger
logging: json

# -- max request timeouts in seconds
timeout: 7200

# used for encrpytion in the following resources: secrets
# if set to empty, one will be generated on install
encryptionKey: "01234567890123456789012345678912"

opentelemetry:
  # -- opentelemetry address where Direktiv is sending data to
  address: "localhost:4317"
  # -- installs opentelemtry agent as sidecar in flow
  enabled: false
  # -- config for sidecar agent
  agentconfig: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
    exporters:
      otlp:
        endpoint: "192.168.1.113:14250"
        insecure: true
        sending_queue:
          num_consumers: 4
          queue_size: 100
        retry_on_failure:
          enabled: true
      logging:
        loglevel: debug
    processors:
      batch:
      memory_limiter:
        # Same as --mem-ballast-size-mib CLI argument
        ballast_size_mib: 165
        # 80% of maximum memory up to 2G
        limit_mib: 400
        # 25% of limit up to 2G
        spike_limit_mib: 100
        check_interval: 5s
    extensions:
      zpages: {}
    service:
      extensions: [zpagui:es]
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch]
          exporters: [logging, otlp]

api:
  replicas: 1

  extraContainers: []
  # -- image for api pod
  image: "direktiv/api"
  # -- image tag for api pod
  tag: ""
  # -- extra container in api pod
  extraContainers: []
  # -- extra volume mounts in api pod
  extraVolumeMounts:
    # - name: service-template
    #   mountPath: /etc/config
  # -- extra volumes in api pod
  extraVolumes:
    # - name: service-template
    #   configMap:
    #     name: service-template
  affinity: {}

networkPolicies:
  # -- adds network policies
  enabled: false
  # -- CIDR for database, excempt from policies
  db: 0.0.0.0/0
  # -- CIDR for services, excempt from policies
  serviceCidr: 0.0.0.0/0
  # -- CIDR for pods, excempt from policies
  podCidr: 0.0.0.0/0

ingress:
  # -- host for external services, only required for TLS
  host: ""
  # -- TLS secret
  certificate: none
  # -- ingress class
  class: "nginx"
  # -- Additional Annotations
  additionalAnnotations: {}

database:
  # -- database host
  host: "postgres-postgresql-ha-pgpool.postgres"
  # -- database port
  port: 5432
  # -- database user
  user: "direktiv"
  # -- database password
  password: "direktivdirektiv"
  # -- database name, auto created if it does not exist
  name: "direktiv"
  # -- sslmode for database
  sslmode: require

fluentbit:
  # -- postgres for direktiv services
  # Append extra output to fluentbit configuration.
  # There are two log types: application (system), functions (workflows)
  # these can be matched to new outputs.
  extraConfig: ""
  # extraConfig: |
  #   [OUTPUT]
  #           name stdout
  #           match application


# -- service account for flow component
serviceAccount:
  annotations: {}
  name: ""
  # example to annotate for GCP database access
  #   annotations:
  #      iam.gke.io/gcp-service-account: IAM_USER@GCP_PROJECT.iam.gserviceaccount.com


# flow config
flow:
  # -- number of flow replicas
  replicas: 1
  # -- image for db update init container
  image: "direktiv/flow-dbinit"
  # -- image for flow pod
  image: "direktiv/flow"
  # -- image tag for flow pod
  tag: ""
  # -- extra container in flow pod
  extraContainers: []
  # -- extra volume mounts in flow pod
  extraVolumeMounts:
    # - name: service-template
    #   mountPath: /etc/config
  # -- extra volumes in flow pod
  extraVolumes:
    # - name: service-template
    #   configMap:
    #     name: service-template
  # -- affinity for flow pods
  affinity: {}
    # podAntiAffinity:
    #   requiredDuringSchedulingIgnoredDuringExecution:
    #   - labelSelector:
    #       matchExpressions:
    #       - key: app.kubernetes.io/name
    #         operator: In
    #         values:
    #         - direktiv
    #     topologyKey: kubernetes.io/hostname


nodeSelector: {}
tolerations: []
affinity: {}

registry: "docker.io"
pullPolicy: Always
imagePullSecrets: []

# -- http proxy settings
http_proxy: ""
# -- https proxy settings
https_proxy: ""
# -- no proxy proxy settings
no_proxy: ""

# -- secrets sidecar in flow pod
secrets:
  image: "direktiv/secrets"
  tag: ""
  db: ""
  extraVolumeMounts: []

# -- UI configuration
ui:
  replicas: 1
  image: "direktiv/ui"
  tag: ""
  certificate: none
  extraContainers: []
  affinity: {}

prometheus:
  install: true
  backendName: "prom-backend-server" # required if install = false
  global:
    scrape_interval: 1m
    evaluation_interval: 1m
  server:
    retention: 96h
    persistentVolume:
      enabled: false
  alertmanager:
    enabled: false
  nodeExporter:
    enabled: false
  pushgateway:
    enabled: false
  kubeStateMetrics:
    enabled: false
  serviceAccounts:
    alertmanager:
      create: false
    nodeExporter:
      create: false
    pushgateway:
      create: false
    server:
      create: true

functions:

  # -- http_proxy injected as environment variable in functions
  http_proxy: ""

  # -- https_proxy injected as environment variable in functions
  https_proxy: ""

  # -- no_proxy injected as environment variable in functions
  no_proxy: ""

  # namespace to run functions in
  namespace: direktiv-services-direktiv
  ingressClass: contour.ingress.networking.knative.dev

  # images for functions controller, knative sidecar and init-pod
  image: "direktiv/functions"
  tag: ""

  sidecar: "direktiv/sidecar"

  initPodImage:  "direktiv/direktiv-init-pod"

  # -- number of controller replicas
  replicas: 1

  # -- Egress/Ingress network limit for functions if supported by network
  netShape: "10M"

  # -- Cleaning up tasks, Kubernetes < 1.20 does not clean finished tasks
  podCleaner: true

  # -- runtime to use, e.g. gvisor on GCP
  runtime: "default"

  affinity: {}

  # -- extra containers for function controller, e.g. database containers for google cloud or logging
  extraContainersPod: []

  # -- extra volumes for tasks and knative pods
  extraVolumes:
    []
  #   - configMap:
  #   name: otel-agent-conf
  #   items:
  #     - key: otel-agent-config
  #       path: otel-agent-config.yaml
  # name: otel-agent-config-vol

  # -- extra containers for tasks and knative pods
  extraContainers:
    []
    # - name: cloud-sql-proxy
    #   image: gcr.io/cloudsql-docker/gce-proxy:1.17
    #   command:
    #     - "/cloud_sql_proxy"
    #     - "-instances=mygcpdb=tcp:5432"
    #     - "-ip_address_types=PRIVATE"
    #   securityContext:
    #     runAsNonRoot: true
    #   resources:
    #     requests:
    #       memory: "2Gi"
    #       cpu:    "1"

# -- enabled api key for the API, key set in http-snippet in `ingress-nginx` none
apikey: none

# -- nginx ingress controller configuration
ingress-nginx:
  install: true
  controller:
    podAnnotations:
      linkerd.io/inject: disabled
    config:
      proxy-buffer-size: "16k"
    replicaCount: 1
    admissionWebhooks:
      patch:
        podAnnotations:
          linkerd.io/inject: disabled
